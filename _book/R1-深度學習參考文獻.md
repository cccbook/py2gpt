# 深度學習參考文獻

## 张浩在路上的文章

* [Attention机制的基本思想与实现原理](https://imzhanghao.com/2021/09/01/attention-mechanism/)
* [详解Self-Attention和Multi-Head Attention](https://imzhanghao.com/2021/09/15/self-attention-multi-head-attention)
* [Encoder-Decoder简介](https://imzhanghao.com/2021/08/26/encoder-decoder/)
* [Attention Is All You Need -- Transformer](https://imzhanghao.com/2021/09/18/transformer/)
